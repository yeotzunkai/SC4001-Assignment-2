{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Imports here\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms, models\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.tensorboard import SummaryWriter \n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "from PIL import Image\n",
    "import json\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = './dataset'\n",
    "train_dir = data_dir + '/train'\n",
    "valid_dir = data_dir + '/valid'\n",
    "test_dir = data_dir + '/test'\n",
    "\n",
    "with open('cat_to_name.json', 'r') as f:\n",
    "    cat_to_name = json.load(f)\n",
    "\n",
    "# Define your transforms for the training, validation, and testing sets\n",
    "train_transforms = transforms.Compose([transforms.RandomRotation(30),\n",
    "                                       transforms.RandomResizedCrop(224),\n",
    "                                       transforms.RandomHorizontalFlip(),\n",
    "                                       transforms.ToTensor(),\n",
    "                                       transforms.Normalize([0.485, 0.456, 0.406], \n",
    "                                                            [0.229, 0.224, 0.225])])\n",
    "\n",
    "test_transforms = transforms.Compose([transforms.Resize(256),\n",
    "                                      transforms.CenterCrop(224),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize([0.485, 0.456, 0.406], \n",
    "                                                           [0.229, 0.224, 0.225])])\n",
    "\n",
    "validation_transforms = transforms.Compose([transforms.Resize(256),\n",
    "                                            transforms.CenterCrop(224),\n",
    "                                            transforms.ToTensor(),\n",
    "                                            transforms.Normalize([0.485, 0.456, 0.406], \n",
    "                                                                 [0.229, 0.224, 0.225])])\n",
    "\n",
    "trainset = torchvision.datasets.ImageFolder(root=train_dir, transform=train_transforms)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle=True, num_workers=0)\n",
    "\n",
    "testset = torchvision.datasets.ImageFolder(root=valid_dir, transform=test_transforms)\n",
    "validloader = torch.utils.data.DataLoader(testset, batch_size=32, shuffle=False, num_workers=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(128 * 56 * 56, 512)  # Adjusted this line\n",
    "        self.fc2 = nn.Linear(512, 102)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.pool(self.relu(self.conv2(x)))\n",
    "        x = self.pool(self.relu(self.conv3(x)))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\User\\OneDrive\\Documents\\GitHub\\SC4001-Assignment-2\\triplet_loss_function.ipynb Cell 4\u001b[0m line \u001b[0;36m8\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/OneDrive/Documents/GitHub/SC4001-Assignment-2/triplet_loss_function.ipynb#X12sZmlsZQ%3D%3D?line=84'>85</a>\u001b[0m         loss\u001b[39m.\u001b[39mbackward()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/OneDrive/Documents/GitHub/SC4001-Assignment-2/triplet_loss_function.ipynb#X12sZmlsZQ%3D%3D?line=85'>86</a>\u001b[0m         optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/User/OneDrive/Documents/GitHub/SC4001-Assignment-2/triplet_loss_function.ipynb#X12sZmlsZQ%3D%3D?line=87'>88</a>\u001b[0m         running_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/OneDrive/Documents/GitHub/SC4001-Assignment-2/triplet_loss_function.ipynb#X12sZmlsZQ%3D%3D?line=89'>90</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEpoch \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m \u001b[39m\u001b[39m+\u001b[39m\u001b[39m \u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m, Loss: \u001b[39m\u001b[39m{\u001b[39;00mrunning_loss\u001b[39m \u001b[39m\u001b[39m/\u001b[39m\u001b[39m \u001b[39m(i\u001b[39m \u001b[39m\u001b[39m+\u001b[39m\u001b[39m \u001b[39m\u001b[39m1\u001b[39m)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/OneDrive/Documents/GitHub/SC4001-Assignment-2/triplet_loss_function.ipynb#X12sZmlsZQ%3D%3D?line=91'>92</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mFinished Training\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "class TripletDataset(Dataset):\n",
    "    def __init__(self, data_dir, transform):\n",
    "        self.data_dir = data_dir\n",
    "        self.transform = transform\n",
    "        self.labels = list(range(len(self.data_dir)))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_dir)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        anchor, anchor_label = self.data_dir[idx]\n",
    "        positive_idx = np.random.choice(len(self.data_dir))\n",
    "        while self.labels[positive_idx] != anchor_label:\n",
    "            positive_idx = np.random.choice(len(self.data_dir))\n",
    "        positive, _ = self.data_dir[positive_idx]\n",
    "\n",
    "        negative_idx = np.random.choice(len(self.data_dir))\n",
    "        while self.labels[negative_idx] == anchor_label:\n",
    "            negative_idx = np.random.choice(len(self.data_dir))\n",
    "        negative, _ = self.data_dir[negative_idx]\n",
    "\n",
    "        # Convert the tensors to PIL Images\n",
    "        anchor = Image.fromarray(anchor.mul(255).byte().numpy().transpose((1, 2, 0)))\n",
    "        positive = Image.fromarray(positive.mul(255).byte().numpy().transpose((1, 2, 0)))\n",
    "        negative = Image.fromarray(negative.mul(255).byte().numpy().transpose((1, 2, 0)))\n",
    "\n",
    "        # Apply the transforms\n",
    "        anchor = self.transform(anchor)\n",
    "        positive = self.transform(positive)\n",
    "        negative = self.transform(negative)\n",
    "\n",
    "        return anchor, positive, negative\n",
    "\n",
    "\n",
    "\n",
    "# Create triplet data loaders\n",
    "triplet_trainset = TripletDataset(trainset, train_transforms)\n",
    "triplet_trainloader = DataLoader(triplet_trainset, batch_size=32, shuffle=True, num_workers=0)\n",
    "\n",
    "class TripletLoss(nn.Module):\n",
    "    def __init__(self, margin=1.0):\n",
    "        super(TripletLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, anchor, positive, negative):\n",
    "        distance_positive = (anchor - positive).pow(2).sum(1)\n",
    "        distance_negative = (anchor - negative).pow(2).sum(1)\n",
    "        loss = torch.clamp(distance_positive - distance_negative + self.margin, min=0.0).mean()\n",
    "        return loss\n",
    "\n",
    "# Create the CNN model\n",
    "cnn_model = CNNModel()\n",
    "cnn_model.to(device)\n",
    "\n",
    "# Define the optimizer and loss function\n",
    "optimizer = optim.Adam(cnn_model.parameters(), lr=0.001)\n",
    "triplet_loss = TripletLoss()\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 3\n",
    "for epoch in range(num_epochs):\n",
    "    cnn_model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for i, data in enumerate(triplet_trainloader, 0):\n",
    "        anchor, positive, negative = data\n",
    "        anchor, positive, negative = anchor.to(device), positive.to(device), negative.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        anchor_output = cnn_model(anchor)\n",
    "        positive_output = cnn_model(positive)\n",
    "        negative_output = cnn_model(negative)\n",
    "\n",
    "        loss = triplet_loss(anchor_output, positive_output, negative_output)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}, Loss: {running_loss / (i + 1)}\")\n",
    "\n",
    "print(\"Finished Training\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
