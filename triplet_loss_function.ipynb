{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports here\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms, models\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.tensorboard import SummaryWriter \n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "from PIL import Image\n",
    "import json\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = './dataset'\n",
    "train_dir = data_dir + '/train'\n",
    "valid_dir = data_dir + '/valid'\n",
    "test_dir = data_dir + '/test'\n",
    "\n",
    "with open('cat_to_name.json', 'r') as f:\n",
    "    cat_to_name = json.load(f)\n",
    "\n",
    "# Define your transforms for the training, validation, and testing sets\n",
    "train_transforms = transforms.Compose([transforms.RandomRotation(30),\n",
    "                                       transforms.RandomResizedCrop(224),\n",
    "                                       transforms.RandomHorizontalFlip(),\n",
    "                                       transforms.ToTensor(),\n",
    "                                       transforms.Normalize([0.485, 0.456, 0.406], \n",
    "                                                            [0.229, 0.224, 0.225])])\n",
    "\n",
    "test_transforms = transforms.Compose([transforms.Resize(256),\n",
    "                                      transforms.CenterCrop(224),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize([0.485, 0.456, 0.406], \n",
    "                                                           [0.229, 0.224, 0.225])])\n",
    "\n",
    "validation_transforms = transforms.Compose([transforms.Resize(256),\n",
    "                                            transforms.CenterCrop(224),\n",
    "                                            transforms.ToTensor(),\n",
    "                                            transforms.Normalize([0.485, 0.456, 0.406], \n",
    "                                                                 [0.229, 0.224, 0.225])])\n",
    "\n",
    "trainset = torchvision.datasets.ImageFolder(root=train_dir, transform=train_transforms)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle=True, num_workers=0)\n",
    "\n",
    "testset = torchvision.datasets.ImageFolder(root=valid_dir, transform=test_transforms)\n",
    "validloader = torch.utils.data.DataLoader(testset, batch_size=32, shuffle=False, num_workers=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(128 * 56 * 56, 512)  # Adjusted this line\n",
    "        self.fc2 = nn.Linear(512, 102)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.pool(self.relu(self.conv2(x)))\n",
    "        x = self.pool(self.relu(self.conv3(x)))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TripletDataset(Dataset):\n",
    "    def __init__(self, data_dir, transform):\n",
    "        self.data_dir = data_dir\n",
    "        self.transform = transform\n",
    "        self.labels = [item[1] for item in self.data_dir]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_dir)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        anchor, anchor_label = self.data_dir[idx]\n",
    "        positive_idx = np.random.choice(len(self.data_dir))\n",
    "        while self.labels[positive_idx] != anchor_label:\n",
    "            positive_idx = np.random.choice(len(self.data_dir))\n",
    "        positive, _ = self.data_dir[positive_idx]\n",
    "\n",
    "        negative_idx = np.random.choice(len(self.data_dir))\n",
    "        while self.labels[negative_idx] == anchor_label:\n",
    "            negative_idx = np.random.choice(len(self.data_dir))\n",
    "        negative, _ = self.data_dir[negative_idx]\n",
    "\n",
    "        anchor = Image.fromarray(anchor.mul(255).byte().numpy().transpose((1, 2, 0)))\n",
    "        positive = Image.fromarray(positive.mul(255).byte().numpy().transpose((1, 2, 0)))\n",
    "        negative = Image.fromarray(negative.mul(255).byte().numpy().transpose((1, 2, 0)))\n",
    "\n",
    "        anchor = self.transform(anchor)\n",
    "        positive = self.transform(positive)\n",
    "        negative = self.transform(negative)\n",
    "\n",
    "        return anchor, positive, negative\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create triplet data loaders\n",
    "triplet_trainset = TripletDataset(trainset, train_transforms)\n",
    "triplet_trainloader = DataLoader(triplet_trainset, batch_size=32, shuffle=True, num_workers=0)\n",
    "validloader = torch.utils.data.DataLoader(testset, batch_size=32, shuffle=False, num_workers=0)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TripletLoss(nn.Module):\n",
    "    def __init__(self, margin=1.0):\n",
    "        super(TripletLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, anchor, positive, negative):\n",
    "        distance_positive = (anchor - positive).pow(2).sum(1)\n",
    "        distance_negative = (anchor - negative).pow(2).sum(1)\n",
    "        loss = torch.clamp(distance_positive - distance_negative + self.margin, min=0.0).mean()\n",
    "        return loss\n",
    "\n",
    "# Create the CNN model\n",
    "cnn_model = CNNModel()\n",
    "cnn_model.to(device)\n",
    "\n",
    "# Define the optimizer and loss function\n",
    "optimizer = optim.Adam(cnn_model.parameters(), lr=0.001)\n",
    "triplet_loss = TripletLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "\n",
    "\n",
    "# Lists to store training and validation losses and accuracies\n",
    "train_losses = []\n",
    "valid_losses = []\n",
    "train_accuracies = []\n",
    "valid_accuracies = []\n",
    "\n",
    "model_checkpoint_path = 'triplet_loss_model.pth'\n",
    "# ...\n",
    "\n",
    "# Inside your training loop\n",
    "for epoch in range(num_epochs):\n",
    "    cnn_model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    # ...\n",
    "\n",
    "    for i, data in enumerate(tqdm(triplet_trainloader), 0):\n",
    "        anchor, positive, negative = data\n",
    "        anchor, positive, negative = anchor.to(device), positive.to(device), negative.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        anchor_output = cnn_model(anchor)\n",
    "        positive_output = cnn_model(positive)\n",
    "        negative_output = cnn_model(negative)\n",
    "\n",
    "        loss = triplet_loss(anchor_output, positive_output, negative_output)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    train_losses.append(running_loss / (i + 1))\n",
    "\n",
    "    torch.save(cnn_model.state_dict(), model_checkpoint_path)\n",
    "\n",
    "    # Calculate training accuracy based on the margin\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(tqdm(triplet_trainloader), 0):\n",
    "            anchor, positive, negative = data\n",
    "            anchor, positive, negative = anchor.to(device), positive.to(device), negative.to(device)\n",
    "            \n",
    "            anchor_output = cnn_model(anchor)\n",
    "            positive_output = cnn_model(positive)\n",
    "            negative_output = cnn_model(negative)\n",
    "            \n",
    "            # Calculate the margin-based accuracy\n",
    "            distance_positive = (anchor_output - positive_output).pow(2).sum(1)\n",
    "            distance_negative = (anchor_output - negative_output).pow(2).sum(1)\n",
    "            correct_train += torch.sum(distance_positive < distance_negative).item()\n",
    "            total_train += anchor.size(0)\n",
    "\n",
    "    train_accuracies.append(correct_train / total_train)\n",
    "   \n",
    "   #validation loop using cross enthropy \n",
    "\n",
    "    cnn_model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct_valid = 0\n",
    "    total_valid = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(validloader, 0):\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            outputs = cnn_model(inputs)\n",
    "            loss = criterion(outputs, labels)  # Use Cross-Entropy Loss\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            # Calculate accuracy\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total_valid += labels.size(0)\n",
    "            correct_valid += (predicted == labels).sum().item()\n",
    "\n",
    "    valid_losses.append(running_loss / (i + 1))\n",
    "    valid_accuracies.append(correct_valid / total_valid)\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}, Loss: {train_losses[-1]}, Training Acc: {train_accuracies[-1]}, Validation Acc: {valid_accuracies[-1]}\")\n",
    "\n",
    "# ...\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'Epoch': range(1, num_epochs + 1),\n",
    "    'Training Loss': train_losses,\n",
    "    'Training Accuracy': train_accuracies,\n",
    "    'Validation Loss': valid_losses,\n",
    "    'Validation Accuracy': valid_accuracies\n",
    "})\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "csv_file = 'triplet_loss_function_metrics.csv'\n",
    "df.to_csv(csv_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After training, you can plot the training and validation losses and accuracies\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.plot(valid_losses, label='Validation Loss')\n",
    "plt.legend()\n",
    "plt.title('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_accuracies, label='Training Accuracy')\n",
    "plt.plot(valid_accuracies, label='Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.title('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create an instance of the CNNModel\n",
    "model = CNNModel()\n",
    "\n",
    "# Load the trained model's state dictionary\n",
    "model.load_state_dict(torch.load('triplet_loss_model.pth'))\n",
    "model.to(device)\n",
    "\n",
    "# Switch the model to evaluation mode\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "model = CNNModel()\n",
    "model.load_state_dict(torch.load('triplet_loss_model.pth'))\n",
    "model.to(device)\n",
    "\n",
    "# Print the model architecture\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "model = CNNModel()\n",
    "model.load_state_dict(torch.load('triplet_loss_model.pth'))\n",
    "model.to(device)\n",
    "\n",
    "# Access the number of output features in the final classification layer (fc2)\n",
    "num_classes = model.fc2.out_features\n",
    "\n",
    "# Print the number of classes\n",
    "print(\"Number of classes:\", num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the mapping from category names to labels\n",
    "with open('cat_to_name.json', 'r') as f:\n",
    "    cat_to_name = json.load(f)\n",
    "\n",
    "# Assuming you have already loaded the model and accessed the number of classes\n",
    "model = CNNModel()\n",
    "model.load_state_dict(torch.load('triplet_loss_model.pth'))\n",
    "model.to(device)\n",
    "\n",
    "num_classes = model.fc2.out_features\n",
    "\n",
    "# Print out all the class names\n",
    "for class_idx in range(num_classes):\n",
    "    class_name = cat_to_name.get(str(class_idx), 'Unknown')\n",
    "    print(f\"Class {class_idx}: {class_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os \n",
    "\n",
    "image_path = \"C:/Users/RZG_TESTER/Documents/GitHub/SC4001-Assignment-2/dataset/test/image_00005.jpg\"\n",
    "\n",
    "image = Image.open(image_path)\n",
    "\n",
    "# Apply the same transformations used during training\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "image = transform(image).unsqueeze(0)  # Add a batch dimension\n",
    "\n",
    "# Move the image to the same device as the model\n",
    "image = image.to(device)\n",
    "\n",
    "# Make a prediction using your model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    output = model(image)\n",
    "\n",
    "# Get the predicted class\n",
    "_, predicted_class = output.max(1)\n",
    "\n",
    "# Map the predicted class index to its label\n",
    "predicted_label = cat_to_name.get(str(predicted_class.item()), 'Unknown')\n",
    "\n",
    "# Move the image tensor to the CPU for NumPy conversion\n",
    "image = image.cpu()\n",
    "\n",
    "# Display the image and its predicted class label\n",
    "plt.imshow(np.array(image.squeeze().permute(1, 2, 0)))\n",
    "plt.title(f'Predicted Class: {predicted_label}')\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "# Define the directory path for the test images\n",
    "test_dir = 'C:/Users/RZG_TESTER/Documents/GitHub/SC4001-Assignment-2/dataset/test'\n",
    "\n",
    "# List all the image files in the test directory\n",
    "image_files = [os.path.join(test_dir, filename) for filename in os.listdir(test_dir) if filename.endswith(('.jpg', '.png', '.jpeg'))]\n",
    "\n",
    "# Randomly select 5 images\n",
    "random_images = random.sample(image_files, 5)\n",
    "\n",
    "# Create a subplot with 1 row and 5 columns\n",
    "fig, axes = plt.subplots(1, 5, figsize=(20, 5))\n",
    "\n",
    "# Function to display an image with its predicted class\n",
    "def display_image(image_path, ax):\n",
    "    image = Image.open(image_path)\n",
    "    image = transform(image).unsqueeze(0)  # Apply the same transformations\n",
    "    image = image.to(device)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output = model(image)\n",
    "\n",
    "    _, predicted_class = output.max(1)\n",
    "    predicted_label = cat_to_name.get(str(predicted_class.item()), 'Unknown')\n",
    "\n",
    "    image = image.cpu()\n",
    "    ax.imshow(np.array(image.squeeze().permute(1, 2, 0)))\n",
    "    ax.set_title(f'Predicted Class: {predicted_label}')\n",
    "    ax.axis('off')\n",
    "\n",
    "# Display the randomly selected images side by side\n",
    "for i, image_path in enumerate(random_images):\n",
    "    display_image(image_path, axes[i])\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(image_path, model_path, topk=5):\n",
    "    image = Image.open(image_path).convert(\"RGB\")  # Remove '.jpg' and add .convert(\"RGB\")\n",
    "\n",
    "    # Define the transformation for the input image\n",
    "    preprocess = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "\n",
    "    image = preprocess(image).unsqueeze(0).to(device)  # Add .to(device)\n",
    "\n",
    "    # Load the model and send it to the same device\n",
    "    model = torch.load(model_path).to(device)\n",
    "\n",
    "    # Ensure the model is in evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Forward pass to get probabilities\n",
    "    with torch.no_grad():\n",
    "        output = model(image)\n",
    "\n",
    "    # Calculate probabilities and top class indices\n",
    "    probs, indices = torch.topk(output, topk)\n",
    "\n",
    "    # Convert indices to class labels\n",
    "    classes = [str(idx.item()) for idx in indices[0]]\n",
    "\n",
    "    return probs[0].cpu().tolist(), classes  # Add .cpu() to move results back to the CPU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "model_path = 'C:/Users/RZG_TESTER/Documents/GitHub/SC4001-Assignment-2/few_shot_learning_model.pth'\n",
    "test_dir = data_dir + '/test'\n",
    "\n",
    "# List all files in the test directory\n",
    "test_files = []\n",
    "for root, dirs, files in os.walk(test_dir):\n",
    "    for file in files:\n",
    "        if file.endswith(\".jpg\"):\n",
    "            test_files.append(os.path.join(root, file).replace('\\\\', '/'))  # Use double backslashes\n",
    "\n",
    "# Randomly select an image from the test directory\n",
    "random_image_path = random.choice(test_files)\n",
    "\n",
    "print(random_image_path)\n",
    "\n",
    "# Getting prediction\n",
    "probs, classes = predict(random_image_path, model_path, topk=5)\n",
    "\n",
    "# Uncomment to check if the class of the flower (as seen from the file path) matches the top one predicted:\n",
    "# print(classes[0])\n",
    "\n",
    "# Converting classes to names\n",
    "names = [cat_to_name[i] for i in classes]\n",
    "\n",
    "# Creating PIL image\n",
    "image = Image.open(random_image_path)\n",
    "\n",
    "# Plotting the random test image and predicted probabilities\n",
    "f, ax = plt.subplots(2, figsize=(6, 10))\n",
    "\n",
    "ax[0].imshow(image)\n",
    "ax[0].set_title(names[0])\n",
    "\n",
    "y_names = np.arange(len(names))\n",
    "ax[1].barh(y_names, probs, color='darkblue')\n",
    "ax[1].set_yticks(y_names)\n",
    "ax[1].set_yticklabels(names)\n",
    "ax[1].invert_yaxis()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get the model's parameters\n",
    "model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "params = [p.numel() for p in model_parameters]\n",
    "\n",
    "# Create labels for each layer\n",
    "layer_labels = [f'Layer {i}' for i in range(1, len(params) + 1)]\n",
    "\n",
    "# Create a bar graph\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.bar(layer_labels, params)\n",
    "plt.xlabel('Model Layers')\n",
    "plt.ylabel('Number of Parameters')\n",
    "plt.title('Number of Parameters in Each Layer')\n",
    "plt.xticks(rotation=45)  # Rotate x-axis labels for better readability\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the graph\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Initialize variables to store true labels and predicted labels\n",
    "true_labels = []\n",
    "predicted_labels = []\n",
    "\n",
    "# Iterate through the validation dataset to collect labels\n",
    "with torch.no_grad():\n",
    "    for images, labels in validloader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        true_labels.extend(labels.cpu().numpy())\n",
    "        predicted_labels.extend(preds.cpu().numpy())\n",
    "\n",
    "# Create the confusion matrix\n",
    "cm = confusion_matrix(true_labels, predicted_labels)\n",
    "\n",
    "# Convert the confusion matrix to a Pandas DataFrame for visualization\n",
    "cm_df = pd.DataFrame(cm, index=cat_to_name.values(), columns=cat_to_name.values())\n",
    "\n",
    "# Create a heatmap of the confusion matrix\n",
    "plt.figure(figsize=(30, 8))\n",
    "sns.heatmap(cm_df, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
